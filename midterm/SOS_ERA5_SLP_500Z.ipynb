{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERA-5 End-to-End Data and Graphics Preparation for the Science-on-a-Sphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will create all the necessary files and directories for a visualization on NOAA's Science-on-a-Sphere. For this example, we will produce a map of 500 hPa geopotential heights and sea-level pressure, using ERA-5 reanalysis, for the January 26 1978 intense surface cyclone, aka *The Cleveland Superbomb*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "\n",
    "1. Set up output directories for SoS\n",
    "1. Programmatically request a specific date from the [RDA ERA-5 THREDDS repository](https://rda.ucar.edu/thredds/catalog/files/g/ds633.0/catalog.html)\n",
    "1. Re-arrange the order of the longitudinal dimension in the dataset\n",
    "1. Use Cartopy's `add_cyclic_point` method to avoid a blank seam at the dateline\n",
    "1. Create small and large thumbnail graphics.\n",
    "1. Create a standalone colorbar\n",
    "1. Create a set of labels for each plot\n",
    "1. Create 24 hours worth of Science-on-a-Sphere-ready plots\n",
    "1. Create an SoS playlist file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| Xarray  | Necessary | |\n",
    "| Linux command line / directory structure | Helpful | |\n",
    "\n",
    "* **Time to learn**: 30 minutes\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import MonthEnd,MonthBegin\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.util as cutil\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not output warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up output directories for SoS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The software that serves output for the Science-on-a-Sphere expects a directory structure as follows:\n",
    "- Top level directory: choose a name that is consistent with your case, e.g.: **cle_superbomb**\n",
    "- 2nd level directory: choose a name that is consistent with the graphic, e.g.: **SLP_500Z**\n",
    "- 3rd level directories: \n",
    "    - **2048**: Contains the graphics (resolution: 2048x1024) that this notebook generates\n",
    "    - **labels**: Contains one or two files:\n",
    "        1. (required) A text file, `labels.txt`, which has as many lines as there are graphics in the **2048** file. Each line functions as the title of each graphic. \n",
    "        1. (optional) A PNG file, `colorbar.png`, which colorbar which will get overlaid on your map graphic.\n",
    "    - **media**: Contains large and small thumbnails (`thumbnail_small.jpg`, `thumbnail_large.jpg`) that serve as icons on the SoS iPad and SoS computer apps\n",
    "    - **playlist**: A text file, `playlist.sos`, which tells the SoS how to display your product\n",
    "    \n",
    "As an example, here is how the directory structure on our SoS looks for the products generated by this notebook. Our SoS computer stores locally-produced content in the `/shared/sos/media/site-custom` directory (note: the SoS directories are not network-accessible, so you won't be able to `cd` into them). The ERA-5 visualizations go in the `ERA5` subfolder. Your top-level directory sits within the `ERA5` folder.\n",
    "\n",
    "```\n",
    "sos@sos1:/shared/sos/media/site-custom/ERA5/cle_superbomb/SLP_500Z$ ls -R\n",
    ".:\n",
    "2048  labels  media  playlist\n",
    "\n",
    "./2048:\n",
    "ERA5_1978012600-fs8.png  ERA5_1978012606-fs8.png  ERA5_1978012612-fs8.png  ERA5_1978012618-fs8.png\n",
    "ERA5_1978012601-fs8.png  ERA5_1978012607-fs8.png  ERA5_1978012613-fs8.png  ERA5_1978012619-fs8.png\n",
    "ERA5_1978012602-fs8.png  ERA5_1978012608-fs8.png  ERA5_1978012614-fs8.png  ERA5_1978012620-fs8.png\n",
    "ERA5_1978012603-fs8.png  ERA5_1978012609-fs8.png  ERA5_1978012615-fs8.png  ERA5_1978012621-fs8.png\n",
    "ERA5_1978012604-fs8.png  ERA5_1978012610-fs8.png  ERA5_1978012616-fs8.png  ERA5_1978012622-fs8.png\n",
    "ERA5_1978012605-fs8.png  ERA5_1978012611-fs8.png  ERA5_1978012617-fs8.png  ERA5_1978012623-fs8.png\n",
    "\n",
    "./labels:\n",
    "colorbar.png  labels.txt\n",
    "\n",
    "./media:\n",
    "thumbnail_big.jpg  thumbnail_small.jpg\n",
    "\n",
    "./playlist:\n",
    "playlist.sos\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the 1st and 2nd-level directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You define these\n",
    "caseDir = 'cle_superbomb'\n",
    "prodDir = 'SLP_500Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3rd-level directories follow from the 1st and 2nd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These remain as is\n",
    "graphicsDir = caseDir + '/' + prodDir + '/2048/'\n",
    "labelsDir = caseDir + '/' + prodDir + '/labels/'\n",
    "mediaDir = caseDir + '/' + prodDir + '/media/'\n",
    "playlistDir = caseDir + '/' + prodDir + '/playlist/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create these directories via a Linux command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p {graphicsDir} {labelsDir} {mediaDir} {playlistDir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Note: </b>In a Jupyter notebook, the <code>!</code> magic indicates that what follows is a Linux command.<br>\n",
    "The <code>-p</code> option for <code>mkdir</code> will create all subdirectories, and also will do nothing if the directories already exist.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmatically request a specific date from the [RDA ERA-5 THREDDS repository](https://rda.ucar.edu/thredds/catalog/files/g/ds633.0/catalog.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next several cells set the date/time, creates the URL strings, and retrieves selected grids from RDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select your date and time here\n",
    "year = 1978\n",
    "month = 1\n",
    "day = 26\n",
    "hour = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <b>One-day limit:</b> <br>\n",
    "    While <b>Xarray</b> can create datasets and data arrays from multiple files, via its <code>open_mfdataset</code> method, this method does not reliably work when reading from a THREDDS server such as RDA's. Therefore, please restrict your temporal range to no more than one calendar day in this notebook.\n",
    "        </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validTime = datetime(year, month, day, hour)\n",
    "YYYYMM = validTime.strftime(\"%Y%m\")\n",
    "YYYYMMDD = validTime.strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the many tools for time series analysis that Pandas provides are functions to determine the first and last days of a month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthEnd = pd.to_datetime(YYYYMM, format='%Y%m') + MonthEnd(0)\n",
    "mEndStr = monthEnd.strftime('%Y%m%d23')\n",
    "\n",
    "monthBeg = pd.to_datetime(YYYYMM, format='%Y%m') + MonthBegin(0)\n",
    "mBegStr = monthBeg.strftime('%Y%m%d00')\n",
    "\n",
    "dayBegStr = YYYYMMDD + '00'\n",
    "dayEndStr = YYYYMMDD + '23'\n",
    "\n",
    "dayBeg = datetime.strptime(dayBegStr, '%Y%m%d%H')\n",
    "dayEnd = datetime.strptime(dayEndStr, '%Y%m%d%H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayBeg, dayEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthBeg, monthEnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the URLs for the various grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SfcURL = []\n",
    "SfcURL.append('https://rda.ucar.edu/thredds/dodsC/files/g/ds633.0/e5.oper.an.')\n",
    "SfcURL.append(YYYYMM + '/e5.oper.an')\n",
    "SfcURL.append('.ll025')\n",
    "SfcURL.append('.' + mBegStr + '_' + mEndStr + '.nc')\n",
    "print(SfcURL)\n",
    "\n",
    "PrsURL = []\n",
    "PrsURL.append('https://rda.ucar.edu/thredds/dodsC/files/g/ds633.0/e5.oper.an.')\n",
    "PrsURL.append(YYYYMM + '/e5.oper.an')\n",
    "PrsURL.append('.ll025')\n",
    "PrsURL.append('.' +  dayBegStr + '_' + dayEndStr + '.nc' )\n",
    "print(PrsURL)\n",
    "\n",
    "ds_urlZ = PrsURL[0] + 'pl/' + PrsURL[1] + '.pl.128_129_z' + PrsURL[2] + 'sc' + PrsURL[3]\n",
    "ds_urlQ = PrsURL[0] + 'pl/' + PrsURL[1] + '.pl.128_133_q' + PrsURL[2] + 'sc' + PrsURL[3]\n",
    "ds_urlT = PrsURL[0] + 'pl/' + PrsURL[1] + '.pl.128_130_t' + PrsURL[2] + 'sc' + PrsURL[3]\n",
    "# Notice that U and V use \"uv\" instead of \"sc\" in their name!\n",
    "ds_urlU = PrsURL[0] + 'pl/' + PrsURL[1] + '.pl.128_131_u' + PrsURL[2] + 'uv' + PrsURL[3]\n",
    "ds_urlV = PrsURL[0] + 'pl/' + PrsURL[1] + '.pl.128_132_v' + PrsURL[2] + 'uv' + PrsURL[3]\n",
    "\n",
    "ds_urlU10 = SfcURL[0] + 'sfc/' + SfcURL[1] + '.sfc.128_165_10u' + SfcURL[2] + 'sc' + SfcURL[3]\n",
    "ds_urlV10 = SfcURL[0] + 'sfc/' + SfcURL[1] + '.sfc.128_166_10v' + SfcURL[2] + 'sc' + SfcURL[3]\n",
    "ds_urlSLP = SfcURL[0] + 'sfc/' + SfcURL[1] + '.sfc.128_151_msl' + SfcURL[2] + 'sc' + SfcURL[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>NOTE:</b> You can find tables listing all of the various parameters in the ERA-5 datasets at <a href='https://rda.ucar.edu/datasets/ds633.0/?hash=access#!docs'> this link</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your RDA credentials to access these individual NetCDF files. You should have previously registered with RDA, and then saved your user id and password in your home directory as .rdarc , with permissions such that only you have read/write access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve login credential for RDA.\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "credFile = open(HOME+'/.rdarc','r')\n",
    "userId, pw = credFile.read().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the RDA THREDDS server and point to the files of interest. Here, we'll comment out the ones we are not interested in but can always uncomment when we want them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.auth = (userId, pw)\n",
    "#storeU10 = xr.backends.PydapDataStore.open(ds_urlU10, session=session)\n",
    "#storeV10 = xr.backends.PydapDataStore.open(ds_urlV10, session=session)\n",
    "storeSLP = xr.backends.PydapDataStore.open(ds_urlSLP, session=session)\n",
    "#storeQ = xr.backends.PydapDataStore.open(ds_urlQ, session=session)\n",
    "#storeT = xr.backends.PydapDataStore.open(ds_urlT, session=session)\n",
    "#storeU = xr.backends.PydapDataStore.open(ds_urlU, session=session)\n",
    "#storeV = xr.backends.PydapDataStore.open(ds_urlV, session=session)\n",
    "storeZ = xr.backends.PydapDataStore.open(ds_urlZ, session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_urlSLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsU10 = xr.open_dataset(storeU10)\n",
    "#dsV10 = xr.open_dataset(storeV10)\n",
    "dsSLP = xr.open_dataset(storeSLP)\n",
    "#dsQ   = xr.open_dataset(storeQ)\n",
    "#dsT   = xr.open_dataset(storeT)\n",
    "#dsU   = xr.open_dataset(storeU)\n",
    "#dsV   = xr.open_dataset(storeV)\n",
    "dsZ   = xr.open_dataset(storeZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The surface fields span the entire month. Let's restrict the range so it matches the day of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsSLP = dsSLP.sel(time=slice(dayBeg,dayEnd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Xarray DataArray object for SLP and perform unit conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLP = dsSLP['MSL']\n",
    "SLP = SLP.metpy.convert_units('hPa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the SLP DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now examine the geopotential data on isobaric surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the memory footprint for data on isobaric surfaces, let's request only 6 out of the 37 available levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsZ = dsZ.sel(level = [200,300,500,700,850,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Xarray DataArray object for Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = dsZ['Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set contour levels for both SLP and Z. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slpLevels = np.arange(864,1080,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a particular isobaric surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pLevel = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine Z so it consists only of the data at the level you just chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = Z.sel(level=pLevel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Science-on-a-Sphere's background maps require that projected images, besides using Plate Carree projection, extend from -180 to +180 degrees longitude. The ERA-5 datasets' longitudinal coordinates start at 0 and go to 360. Although we won't be using those maps (instead, we will add map borders to our graphic using Cartopy), let's define a function that re-sorts datasets (or data arrays) so the longitudinal range begins at the dateline instead of the Greenwich meridian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reSortCoords(d):\n",
    "    longitudeName = 'longitude'\n",
    "    d.coords[longitudeName] = (d.coords[longitudeName] + 180) % 360 - 180\n",
    "    d = d.sortby(d[longitudeName])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = reSortCoords(Z)\n",
    "SLP = reSortCoords(SLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine one of the re-sorted data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the longitude dimension now begins at -180."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of plotting geopotential heights in decameters, choose an appropriate contour interval and range of values ... for geopotential heights, a common convention is: from surface up through 700 hPa: 3 dam; above that, 6 dam to 400 and then 9 or 12 dam from 400 and above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (pLevel == 1000):\n",
    "    zLevels= np.arange(-90,63, 3)\n",
    "elif (pLevel == 850):\n",
    "    zLevels = np.arange(60, 183, 3)\n",
    "elif (pLevel == 700):\n",
    "    zLevels = np.arange(201, 339, 3)\n",
    "elif (pLevel == 500):\n",
    "    zLevels = np.arange(468, 606, 6)\n",
    "elif (pLevel == 300):\n",
    "    zLevels = np.arange(765, 1008, 9)\n",
    "elif (pLevel == 200): \n",
    "    zLevels = np.arange(999, 1305, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">In this notebook, we did not retrieve the U- and V- wind component grids. However, if you end up modifying this notebook to do so, uncomment the lines in the following cell.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (U.units)\n",
    "## Convert wind from m/s to knots; use MetPy to calculate the wind speed.\n",
    "#UKts = U.metpy.convert_units('knots')\n",
    "#VKts = V.metpy.convert_units('knots')\n",
    "## Calculate windspeed.\n",
    "#wspdKts = calc.wind_speed(U,V).to('knots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create objects for the relevant coordinate arrays; in this case, *longitude*, *latitude*, and *time*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons, lats, times= SLP.longitude, SLP.latitude, SLP.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a peek at a couple of these coordinate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">Notice that the longitudinal array extends to 179.75, not 180. We will use Cartopy's <code>add_cyclic_point</code> method to eliminate the resulting seam.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create contour plots of SLP and geopotential height.\n",
    "Let's create a plot for a single time, just to ensure all looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_data = ccrs.PlateCarree() # The dataset's x- and y- coordinates are lon-lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Note: </b>The Science on a Sphere treats titles and colorbars as separate layers. Thus, in this next cell we will not generate nor include them in the figure.<br>\n",
    "Additionally, the sphere expects its graphics to have a resolution of 2048x1024.<br>\n",
    "Finally, by default, Matplotlib includes a border frame around each <code>Axes</code>. We don't want that included on the sphere-projected graphic either.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res = '110m'\n",
    "dpi = 100\n",
    "fig = plt.figure(figsize=(2048/dpi, 1024/dpi))\n",
    "ax = plt.subplot(1,1,1,projection=ccrs.PlateCarree(), frameon=False)\n",
    "ax.set_global()\n",
    "ax.add_feature(cfeature.COASTLINE.with_scale(res))\n",
    "ax.add_feature(cfeature.BORDERS.with_scale(res))\n",
    "ax.add_feature(cfeature.STATES.with_scale(res))\n",
    "\n",
    "# Convert from units of geopotential to height in decameters.\n",
    "Zdam = mpcalc.geopotential_to_height(Z.isel(time=0)).metpy.convert_units('dam')\n",
    "\n",
    "# add cyclic points to data and longitudes\n",
    "# latitudes are unchanged in 1-dimension\n",
    "SLP2d, clons= cutil.add_cyclic_point(SLP.isel(time=0), lons)\n",
    "z2d, clons = cutil.add_cyclic_point(Zdam, lons)\n",
    "\n",
    "# Height (Z) contour fills\n",
    "\n",
    "# Note we don't need the transform argument since the map/data projections are the same, but we'll leave it in\n",
    "CF = ax.contourf(clons,lats,z2d,levels=zLevels,cmap=plt.get_cmap('viridis'), extend='both', transform=proj_data) \n",
    "\n",
    "# SLP contour lines\n",
    "CL = ax.contour(clons,lats,SLP2d,slpLevels,linewidths=1.25,colors='chocolate', transform=proj_data)\n",
    "ax.clabel(CL, inline_spacing=0.2, fontsize=8, fmt='%.0f')\n",
    "fig.tight_layout(pad=.01)\n",
    "\n",
    "# Save this figure to your current directory\n",
    "fig.savefig('test_ERA_SOS.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you'd like, go to https://maptoglobe.com and view how your graphic might look on the sphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b>Note:</b> If you get an error message from the <i>maptoglobe.com</i> site, try reloading. Usually it will load correctly on the 2nd try.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow these steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">You can find screenshots of some of these steps at the [Jupyterbook version of this notebook]()</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the `test_ERA5_SOS.png` file to your local computer\n",
    "1. Click on the **Images** tab on the *maptoglobe* site\n",
    "1. Next to **Surface**, click on *Choose a file*\n",
    "1. Navigate to the folder in which you downloaded the PNG, select the PNG, and click on **OK**\n",
    "1. You should then see your map! Use your mouse to move the globe around; also use the mouse wheel to zoom in and out.\n",
    "1. If the image looks good, you're ready to move forward!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the following after successfully connecting to the *maptoglobe* site:\n",
    "<center><img src=\"../images/maptoglobe1.png\" alt=\"M2G\" style=\"width: 350px;\"/></center>\n",
    "\n",
    "\n",
    "Then, follow these steps:\n",
    "1. Download the `test_ERA5_SOS.png` file to your local computer\n",
    "1. Click on the **Images** tab on the *maptoglobe* site\n",
    "1. Next to **Surface**, click on *Choose a file*\n",
    "<center><img src=\"../images/MtGChooseSurface.png\" alt=\"M2GSfcChoose\" style=\"width: 350px;\"/></center>\n",
    "1. Navigate to the folder in which you downloaded the PNG, select the PNG, and click on **OK**\n",
    "<center><img src=\"../images/MtGSelectPNG.png\" alt=\"M2GSelectPNG\" style=\"width: 350px;\"/></center>\n",
    "1. You should then see your map! Use your mouse to move the globe around; also use the mouse wheel to zoom in and out.\n",
    "<center><img src=\"../images/MtGView.png\" alt=\"M2GView\" style=\"width: 350px;\"/></center>\n",
    "1. If the image looks good, you're ready to move forward!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create small (128x128) and large (800x800) thumbnails. These will serve as icons in the SoS iPad and computer apps that go along with your particular product.\n",
    "We'll use the orthographic projection and omit the contour lines and some of the cartographic features, and add a title string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = '110m'\n",
    "dpi = 100\n",
    "for size in (128, 800):\n",
    "    if (size == 128):\n",
    "        sizeStr = 'small'\n",
    "    else:\n",
    "        sizeStr ='big'\n",
    "        \n",
    "    fig = plt.figure(figsize=(size/dpi, size/dpi))\n",
    "    ax = plt.subplot(1,1,1,projection=ccrs.Orthographic(central_longitude=-90), frameon=False)\n",
    "    ax.set_global()\n",
    "    ax.add_feature(cfeature.COASTLINE.with_scale(res))\n",
    "    tl1 = caseDir\n",
    "    tl2 = prodDir\n",
    "    ax.set_title(tl1 + '\\n' + tl2, color='purple', fontsize=8)\n",
    "\n",
    "    # Height (Z) contour fills\n",
    "\n",
    "    CF = ax.contourf(clons,lats,z2d,levels=zLevels,cmap=plt.get_cmap('viridis'), extend='both', transform=proj_data) \n",
    "\n",
    "    fig.tight_layout(pad=.01)\n",
    "    fig.savefig(mediaDir + 'thumbnail_' + sizeStr + '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a standalone colorbar\n",
    "Visualizations on the Science-on-a-Sphere consist of a series of image files, layered on top of each other. In this example, instead of having the colorbar associated with 500 hPa heights adjacent to the map, let's use a technique by which we remove the contour plot, leaving only the colorbar to be exported as an image. We change the colorbar's orientation to horizontal, and also change its tick label colors so they will be more visible on the sphere's display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a new figure and replot the colorbar there\n",
    "fig,ax = plt.subplots(figsize=(14,2), dpi=125)\n",
    "# set tick and ticklabel color\n",
    "tick_color='black'\n",
    "label_color='orange'\n",
    "cbar = fig.colorbar(CF, ax=ax, orientation='horizontal')\n",
    "cbar.ax.xaxis.set_tick_params(color=tick_color, labelcolor=label_color)\n",
    "# Remove the Axes object ... essentially the contours and cartographic features ... from the figure.\n",
    "ax.remove()\n",
    "# All that remains is the colorbar ... save it to disk. Make the background transparent.\n",
    "fig.savefig(labelsDir + 'colorbar.png',transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a set of labels for each plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFname = labelsDir + 'labels.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to create the plot for each hour. \n",
    "The function accepts the hour and a <code>DataArray</code> as its arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sos_map (i, z):\n",
    "    res = '110m'\n",
    "    dpi = 100\n",
    "    fig = plt.figure(figsize=(2048/dpi, 1024/dpi))\n",
    "    ax = plt.subplot(1,1,1,projection=ccrs.PlateCarree(), frameon=False)\n",
    "    ax.set_global()\n",
    "    ax.add_feature(cfeature.COASTLINE.with_scale(res))\n",
    "    ax.add_feature(cfeature.BORDERS.with_scale(res))\n",
    "    ax.add_feature(cfeature.STATES.with_scale(res))\n",
    "\n",
    "    # add cyclic points to data and longitudes\n",
    "    # latitudes are unchanged in 1-dimension\n",
    "    SLP2d, clons= cutil.add_cyclic_point(SLP.isel(time=i), lons)\n",
    "    z2d, clons = cutil.add_cyclic_point(z, lons)\n",
    "\n",
    "    # Height (Z) contour fills\n",
    "\n",
    "    CF = ax.contourf(clons,lats,z2d,levels=zLevels,cmap=plt.get_cmap('viridis'), extend='both') \n",
    "\n",
    "    # SLP contour lines\n",
    "    CL = ax.contour(clons,lats,SLP2d,slpLevels,linewidths=1.25,colors='chocolate', transform=proj_data)\n",
    "    ax.clabel(CL, inline_spacing=0.2, fontsize=8, fmt='%.0f')\n",
    "    fig.tight_layout(pad=.01)\n",
    "    frameNum = str(i).zfill(2)\n",
    "    figName = graphicsDir + \"ERA5_\"+ YYYYMMDD + frameNum + '.png'\n",
    "    fig.savefig(figName)\n",
    "    \n",
    "    # Reduce the size of the PNG image via the Linux pngquant utility. The -f option overwites the resulting file if it already exists.\n",
    "    # The output file will end in \"-fs8.png\"\n",
    "    ! pngquant -f {figName}\n",
    "    \n",
    "    # Remove the original PNG\n",
    "    ! rm -f {figName}\n",
    "    \n",
    "    # Do not show the graphic in the notebook\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">When making your own products, modify/eliminate the line that performs unit conversions depending on what scalar/vector you wish to plot. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the graphics and titles\n",
    "- Open a handle to the labels file\n",
    "- Define the time dimension index's start, end, and increment values\n",
    "- Loop over the 24 hours\n",
    "  - Perform any necessary unit conversions\n",
    "  - Create each hour's graphic\n",
    "  - Write the title line to the text file.\n",
    "- Close the handle to the labels file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">For demonstration purposes, we will use a time increment of <b>12</b> hours ... thus only <b>2</b> graphics will be produced. When you are ready, change the <code>inc</code> to <b>1</b> so all hours are processed. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFileObject = open(labelFname, 'w')\n",
    "startHr = 0\n",
    "endHr = 24\n",
    "inc = 12 # Change to 1 when ready\n",
    "\n",
    "for time in range(startHr, endHr, inc):\n",
    "    \n",
    "    # Perform any unit conversions appropriate for your scalar quantities. In this example,\n",
    "    # we convert geopotential to geopotential height in decameters.\n",
    "\n",
    "    z = mpcalc.geopotential_to_height(Z.isel(time=time)).metpy.convert_units('dam')\n",
    "    make_sos_map(time,z)\n",
    "    \n",
    "    # Construct the title string and write it to the file\n",
    "    valTime = pd.to_datetime(times[time].values).strftime(\"%m/%d/%Y %H UTC\")\n",
    "    tl1 = str(\"ERA-5 SLP & \" + str(pLevel) + \" hPa Z \" + valTime + \"\\n\") # \\n is the newline character\n",
    "    labelFileObject.write(tl1)\n",
    "    print(tl1)\n",
    "# Close the text file\n",
    "labelFileObject.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the file handles to the remote RDA THREDDS server.\n",
    "Modify as needed ... close whatever `Dataset` objects you created via Xarray's `open_dataset` method earlier in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsSLP.close()\n",
    "dsZ.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an SoS playlist file\n",
    "We follow the guidelines in https://sos.noaa.gov/support/sos/manuals/datasets/playlists/#dataset-playlist.sos-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlistFname = playlistDir + 'playlist.sos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open a file handle to the playlist file\n",
    "- Add each line of the playlist. *Modify as needed for your case and product; in general you will only need to modify the **name** and **description** values!*\n",
    "- Close the file handle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plFileObject = open(playlistFname, 'w')\n",
    "\n",
    "cRet = \"\\n\" # New line character code\n",
    "nameStr = \"Cleveland Superbomb 1978 SLP/500 Z\"\n",
    "descriptionStr = '{{ ERA-5 January 26 1978 (\"Cleveland Superbomb\") }}'\n",
    "plFileObject.write(\"name = \" + nameStr + cRet )\n",
    "plFileObject.write(\"description = \" + descriptionStr + cRet)\n",
    "\n",
    "plFileObject.write(\"pip = ../labels/colorbar.png\" + cRet)\n",
    "plFileObject.write(\"pipheight = 12\" + cRet)\n",
    "plFileObject.write(\"pipvertical = -35\" + cRet)\n",
    "\n",
    "plFileObject.write(\"label = ../labels/labels.txt\" + cRet)\n",
    "plFileObject.write(\"layer = Grids\" + cRet)\n",
    "plFileObject.write(\"layerdata = ../2048\" + cRet)\n",
    "\n",
    "plFileObject.write(\"firstdwell = 2000\" + cRet)\n",
    "plFileObject.write(\"lastdwell = 3000\" + cRet)\n",
    "plFileObject.write(\"fps = 8\" + cRet)\n",
    "\n",
    "plFileObject.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the contents of the playlist file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat {playlistFname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">The playlist essentially describes the following:\n",
    "<ol><li>The name and description of the product, which are used in the SoS iPad and computer apps</li>\n",
    "    <li>The three components of what is displayed on the screen:</li>\n",
    "    <ol><li>The colorbar (a <i>picture-in-picture</i>, aka <b>pip</b>), with its height and vertical position</li>\n",
    "        <li>The label, or title, which describes the graphic</li>\n",
    "        <li>The graphic layer itself. <i>Multiple graphic layers, each with its own layer name and directory path, could be included; in this case, there is just one.</i></li></ol>\n",
    "    <li>The dwell times, in ms, for the first frame, last frame, and all frames in-between.</li></ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're done! The directory tree you have created can then be copied/synced to the correct directory on the SoS computer. A scheduled `cron` job on that computer will monitor your case directory for changes, and perform the copy/sync periodically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "We now have an end-to-end workflow that will create all that is necessary for a custom SoS visualization, using ERA-5 reanalysis data.\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "Use this notebook as a template for your own case and its accompanying visualizations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 August 2022 Environment",
   "language": "python",
   "name": "aug22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
